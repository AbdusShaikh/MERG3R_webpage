<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="MERG3R: A Divide-and-Conquer Approach to Large-Scale Neural Visual Geometry - Leo Kaixuan Cheng, Abdus Shaikh, Ruofan Liang, Zhijie Wu, Yushi Guan, Nandita Vijaykumar">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="Recent advancements in neural visual geometry, including transformer-based models such as VGGT and Pi3, have achieved impressive accuracy on 3D reconstruction tasks. However, their reliance on full attention makes them fundamentally limited by GPU memory capacity, preventing them from scaling to large, unordered image collections. We introduce MERG3R, a training-free divide-and-conquer framework that enables geometric foundation models to operate far beyond their native memory limits. MERG3R first reorders and partitions unordered images into overlapping, geometrically diverse subsets that can be reconstructed independently. It then merges the resulting local reconstructions through an efficient global alignment and confidence-weighted bundle adjustment procedure, producing a globally consistent 3D model. Our framework is model-agnostic and can be paired with existing neural geometry models. Across large-scale datasets—including 7-Scenes, NRGBD, Tanks & Temples, and Cambridge Landmarks—MERG3R consistently improves reconstruction accuracy, memory efficiency, and scalability, enabling high-quality reconstruction when the dataset exceeds memory capacity limits.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="computer vision, computer graphics, machine learning, structure from motion, 3d reconstruction, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Leo Kaixuan Cheng , Abdus Shaikh, Ruofan Liang, Zhijie Wu, Yushi Guan, Nandita Vijaykumar">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="University Of Toronto">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="MERG3R: A Divide-and-Conquer Approach to Large-Scale Neural Visual Geometry">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="Recent advancements in neural visual geometry, including transformer-based models such as VGGT and Pi3, have achieved impressive accuracy on 3D reconstruction tasks. However, their reliance on full attention makes them fundamentally limited by GPU memory capacity, preventing them from scaling to large, unordered image collections. We introduce MERG3R, a training-free divide-and-conquer framework that enables geometric foundation models to operate far beyond their native memory limits. MERG3R first reorders and partitions unordered images into overlapping, geometrically diverse subsets that can be reconstructed independently. It then merges the resulting local reconstructions through an efficient global alignment and confidence-weighted bundle adjustment procedure, producing a globally consistent 3D model. Our framework is model-agnostic and can be paired with existing neural geometry models. Across large-scale datasets—including 7-Scenes, NRGBD, Tanks & Temples, and Cambridge Landmarks—MERG3R consistently improves reconstruction accuracy, memory efficiency, and scalability, enabling high-quality reconstruction when the dataset exceeds memory capacity limits.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>MERG3R: A Divide-and-Conquer Approach to Large-Scale Neural Visual Geometry - Leo Kaixuan Cheng , Abdus Shaikh, Ruofan Liang, Zhijie Wu, Yushi Guan, Nandita Vijaykumar | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Space+Mono:ital,wght@0,400;0,700;1,400&family=Syne:wght@400;600;700;800&family=DM+Sans:ital,opsz,wght@0,9..40,300;0,9..40,400;0,9..40,500;1,9..40,300&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>

<style>
/* ============================================================
   MERG3R — Visual Enhancement Layer
   Aesthetic: Deep Space / Scientific Precision
   Dark hero, electric blue accents, particle field, 
   sharp type, smooth reveal animations
   ============================================================ */

:root {
  --black:     #080c12;
  --dark:      #0d1420;
  --panel:     #111827;
  --border:    rgba(99,179,237,0.18);
  --blue:      #63b3ed;
  --blue-glow: #3b82f6;
  --cyan:      #67e8f9;
  --white:     #f0f6ff;
  --muted:     #94a3b8;
  --font-display: 'Syne', sans-serif;
  --font-mono:    'Space Mono', monospace;
  --font-body:    'DM Sans', sans-serif;
}

/* ── Global reset on top of Bulma ── */
body {
  background: var(--black);
  color: var(--white);
  font-family: var(--font-body);
  font-weight: 300;
  overflow-x: hidden;
}

/* ── Canvas particle background ── */
#particle-canvas {
  position: fixed;
  top: 0; left: 0;
  width: 100%; height: 100%;
  pointer-events: none;
  z-index: 0;
  opacity: 0.45;
}

/* ── All sections sit above canvas ── */
section, footer, .more-works-container, .scroll-to-top {
  position: relative;
  z-index: 1;
}

/* ── Hero — dark, full bleed ── */
.hero {
  background: transparent !important;
}

.hero.teaser {
  background: transparent !important;
}

.hero.is-light {
  background: var(--panel) !important;
  border-top: 1px solid var(--border);
  border-bottom: 1px solid var(--border);
}

.hero.is-small.is-light {
  background: var(--dark) !important;
}

/* ── Publication title ── */
.publication-title {
  font-family: var(--font-display) !important;
  font-weight: 800 !important;
  font-size: clamp(1.8rem, 4vw, 3rem) !important;
  color: var(--white) !important;
  line-height: 1.15 !important;
  letter-spacing: -0.02em;
}

/* Highlight the "3" in MERG3R */
.publication-title .highlight-3 {
  color: var(--blue);
  text-shadow: 0 0 24px rgba(99,179,237,0.6);
  font-family: inherit !important;
  font-size: inherit !important;
  font-weight: inherit !important;
  line-height: inherit !important;
  vertical-align: baseline !important;
  display: inline !important;
  position: static !important;
  top: auto !important;
  /* Reset any Bulma helpers */
  padding: 0 !important;
  margin: 0 !important;
}

/* ── Author names ── */
.publication-authors, .publication-authors a {
  color: var(--muted) !important;
  font-family: var(--font-body) !important;
}
.publication-authors a:hover {
  color: var(--blue) !important;
  transition: color 0.2s;
}

/* ── Author-block institution line ── */
.author-block span {
  color: var(--muted) !important;
}

/* ── Action buttons ── */
.button.is-dark {
  background: transparent !important;
  border: 1px solid var(--border) !important;
  color: var(--white) !important;
  font-family: var(--font-mono) !important;
  font-size: 0.75rem !important;
  letter-spacing: 0.05em;
  transition: all 0.25s ease !important;
  backdrop-filter: blur(6px);
}
.button.is-dark:hover {
  background: rgba(99,179,237,0.12) !important;
  border-color: var(--blue) !important;
  color: var(--blue) !important;
  box-shadow: 0 0 18px rgba(99,179,237,0.25) !important;
  transform: translateY(-2px);
}

/* ── Section titles ── */
.title.is-3, .title {
  font-family: var(--font-display) !important;
  font-weight: 700 !important;
  color: var(--white) !important;
  letter-spacing: -0.01em;
}

/* ── Section title hover: letter-split effect ── */
h2.title.is-3, h2.title:not(.publication-title) {
  cursor: default;
  display: block;
}
h2.title.is-3 .char, h2.title:not(.publication-title) .char {
  display: inline-block;
  transition: transform 0.3s ease, color 0.3s ease, text-shadow 0.3s ease;
  transform-origin: center bottom;
}
h2.title.is-3:hover .char, h2.title:not(.publication-title):hover .char {
  color: var(--blue);
  text-shadow: 0 0 20px rgba(99,179,237,0.7), 0 0 40px rgba(99,179,237,0.3);
  animation: char-wave 0.5s ease forwards;
}
@keyframes char-wave {
  0%   { transform: translateY(0)    scaleX(1); }
  30%  { transform: translateY(-8px) scaleX(0.95); }
  60%  { transform: translateY(3px)  scaleX(1.02); }
  100% { transform: translateY(0)    scaleX(1); }
}

h2.title {
  text-align: center !important;
}
h2.title::after {
  content: '';
  display: block;
  height: 2px;
  background: linear-gradient(90deg, #a855f7, #ec4899);
  margin: 0.5rem auto 0;
  border-radius: 2px;
  width: var(--underline-width, 8rem);
  transition: width 0.4s cubic-bezier(0.25, 0.46, 0.45, 0.94), opacity 0.4s ease;
}
h2.title:hover::after {
  width: calc(var(--underline-width, 8rem) + 3rem);
  opacity: 0.75;
}

/* ── Body text ── */
.content p, .subtitle {
  color: #c4d0e0 !important;
  font-family: var(--font-body) !important;
  font-size: 1.05rem !important;
  line-height: 1.8 !important;
}

/* ── Teaser image glow ── */
.hero.teaser img {
  border-radius: 12px;
  box-shadow: 0 0 60px rgba(59,130,246,0.2), 0 2px 40px rgba(0,0,0,0.6);
  border: 1px solid var(--border);
  transition: box-shadow 0.4s ease;
}
.hero.teaser img:hover {
  box-shadow: 0 0 90px rgba(99,179,237,0.35), 0 4px 60px rgba(0,0,0,0.7);
}

/* ── Method image ── */
#tree {
  border-radius: 10px;
  border: 1px solid var(--border);
  box-shadow: 0 0 40px rgba(59,130,246,0.15);
}

/* ── Carousel navigation buttons ── */
.carousel-arrow,
.slider-navigation-previous,
.slider-navigation-next,
#results-carousel ~ .carousel-arrow,
.carousel .carousel-arrow {
  background: rgba(13,20,32,0.85) !important;
  border: 1px solid var(--border) !important;
  color: var(--blue) !important;
  box-shadow: 0 0 16px rgba(59,130,246,0.2) !important;
  backdrop-filter: blur(6px) !important;
  transition: all 0.2s !important;
}
.carousel-arrow:hover,
.slider-navigation-previous:hover,
.slider-navigation-next:hover {
  background: rgba(99,179,237,0.12) !important;
  border-color: var(--blue) !important;
  box-shadow: 0 0 24px rgba(99,179,237,0.4) !important;
}
.carousel-arrow .icon, .carousel-arrow i,
.slider-navigation-previous .icon, .slider-navigation-previous i,
.slider-navigation-next .icon, .slider-navigation-next i {
  color: var(--blue) !important;
}
/* Carousel dots */
.carousel-indicator li,
.slider-pagination-list li {
  background: var(--border) !important;
  border-color: var(--border) !important;
}
.carousel-indicator li.is-active,
.slider-pagination-list li.is-active {
  background: var(--blue) !important;
  border-color: var(--blue) !important;
  box-shadow: 0 0 8px rgba(99,179,237,0.5) !important;
}
  border-radius: 10px;
  border: 1px solid var(--border);
}

/* ── Video player ── */
.publication-video video,
.publication-video iframe {
  border-radius: 10px;
  border: 1px solid var(--border);
  box-shadow: 0 0 40px rgba(59,130,246,0.2);
}

/* ── BibTeX block ── */
#BibTeX {
  background: var(--dark) !important;
}
#BibTeX .title {
  color: var(--white) !important;
}
#bibtex-code {
  background: #0a0f1a !important;
  border: 1px solid var(--border) !important;
  border-radius: 10px !important;
  padding: 1.5rem !important;
  font-family: var(--font-mono) !important;
  font-size: 0.82rem !important;
  color: #93c5fd !important;
  line-height: 1.7;
  position: relative;
  overflow-x: auto;
}
#bibtex-code::before {
  content: 'BibTeX';
  position: absolute;
  top: 0.6rem; right: 0.9rem;
  font-family: var(--font-mono);
  font-size: 0.65rem;
  color: var(--blue);
  letter-spacing: 0.1em;
  text-transform: uppercase;
  opacity: 0.6;
}

.copy-bibtex-btn {
  background: transparent !important;
  border: 1px solid var(--border) !important;
  color: var(--blue) !important;
  font-family: var(--font-mono) !important;
  font-size: 0.75rem !important;
  border-radius: 6px;
  padding: 0.4rem 0.9rem;
  cursor: pointer;
  transition: all 0.2s;
}
.copy-bibtex-btn:hover {
  background: rgba(99,179,237,0.1) !important;
  box-shadow: 0 0 12px rgba(99,179,237,0.3);
}
.bibtex-header {
  display: flex;
  align-items: center;
  justify-content: flex-end;
  margin-bottom: 0.6rem;
}

/* ── Footer ── */
footer.footer {
  background: #06080f !important;
  border-top: 1px solid var(--border);
  color: var(--muted) !important;
}
footer .content p, footer a {
  color: var(--muted) !important;
  font-size: 0.88rem !important;
}
footer a:hover { color: var(--blue) !important; }

/* ── Scroll-to-top ── */
.scroll-to-top {
  background: var(--panel) !important;
  border: 1px solid var(--border) !important;
  color: var(--blue) !important;
  box-shadow: 0 0 20px rgba(59,130,246,0.2) !important;
  transition: all 0.25s !important;
}
.scroll-to-top:hover {
  background: rgba(99,179,237,0.12) !important;
  box-shadow: 0 0 30px rgba(99,179,237,0.4) !important;
  transform: translateY(-3px);
}

/* ── More Works panel ── */
.more-works-btn {
  background: var(--panel) !important;
  border: 1px solid var(--border) !important;
  color: var(--white) !important;
  font-family: var(--font-body) !important;
  transition: all 0.25s !important;
}
.more-works-btn:hover {
  background: rgba(99,179,237,0.1) !important;
  border-color: var(--blue) !important;
  color: var(--blue) !important;
}
.more-works-dropdown {
  background: var(--panel) !important;
  border: 1px solid var(--border) !important;
  box-shadow: 0 8px 40px rgba(0,0,0,0.6) !important;
}
.dropdown-header h4 {
  color: var(--white) !important;
  font-family: var(--font-display) !important;
}
.work-item {
  border-bottom: 1px solid var(--border) !important;
  transition: background 0.2s !important;
}
.work-item:hover {
  background: rgba(99,179,237,0.06) !important;
}
.work-item h5 { color: var(--white) !important; }
.work-item p  { color: var(--muted) !important; }
.work-venue   { color: var(--blue) !important; }

/* ── Scan-line overlay on hero ── */
.hero-body::before {
  display: none;
}
.hero:first-of-type .hero-body {
  padding-top: 5rem;
  padding-bottom: 4rem;
}

/* ── Animated gradient accent bar behind title ── */
.hero-accent-bar {
  display: block;
  height: 3px;
  width: 80px;
  background: linear-gradient(90deg, var(--blue-glow), var(--cyan));
  border-radius: 2px;
  margin: 0.8rem auto 1.4rem;
  transition: width 0.15s ease-out, opacity 0.15s ease-out;
  opacity: 0.7;
}

/* ── Conference badge ── */
.coord-tag {
  font-family: var(--font-mono);
  font-size: 0.75rem;
  color: var(--cyan);
  letter-spacing: 0.18em;
  display: inline-block;
  margin-bottom: 1rem;
  padding: 0.3rem 0.9rem;
  border: 1px solid rgba(103,232,249,0.35);
  border-radius: 100px;
  background: rgba(103,232,249,0.06);
  text-transform: uppercase;
}

/* ── Scroll-reveal ── */
.reveal {
  opacity: 0;
  transform: translateY(28px);
  transition: opacity 0.65s ease, transform 0.65s ease;
}
.reveal.visible {
  opacity: 1;
  transform: translateY(0);
}
.reveal-delay-1 { transition-delay: 0.1s; }
.reveal-delay-2 { transition-delay: 0.2s; }
.reveal-delay-3 { transition-delay: 0.35s; }
.reveal-delay-4 { transition-delay: 0.5s; }

/* ── Section label (mono tag above headings) ── */
.section-label {
  font-family: var(--font-mono);
  font-size: 0.65rem;
  letter-spacing: 0.2em;
  text-transform: uppercase;
  color: var(--blue);
  opacity: 0.7;
  display: block;
  margin-bottom: 0.4rem;
}

/* ── Stat chips ── */
.stat-chips {
  display: flex;
  flex-wrap: wrap;
  gap: 0.6rem;
  justify-content: center;
  margin: 1.8rem 0 0;
}
.stat-chip {
  font-family: var(--font-mono);
  font-size: 0.72rem;
  padding: 0.35rem 0.85rem;
  border: 1px solid var(--border);
  border-radius: 100px;
  color: var(--cyan);
  background: rgba(103,232,249,0.05);
  letter-spacing: 0.06em;
  white-space: nowrap;
  transition: all 0.2s;
}
.stat-chip:hover {
  background: rgba(103,232,249,0.12);
  border-color: var(--cyan);
  box-shadow: 0 0 14px rgba(103,232,249,0.2);
}

/* ── Glowing section divider ── */
.glow-divider {
  border: none;
  height: 1px;
  background: linear-gradient(90deg, transparent, var(--blue), transparent);
  margin: 0;
  opacity: 0.35;
}

/* ── eql-cntrb ── */
.eql-cntrb small { color: var(--muted) !important; }

/* scrollbar */
::-webkit-scrollbar { width: 6px; }
::-webkit-scrollbar-track { background: var(--black); }
::-webkit-scrollbar-thumb { background: #1e3a5f; border-radius: 3px; }
::-webkit-scrollbar-thumb:hover { background: var(--blue); }

</style>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">MERG3R: A Divide-and-Conquer Approach to Large-Scale Neural Visual Geometry</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Leo Kaixuan Cheng</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Abdus Shaikh</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Ruofan Liang</a>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Zhijie Wu</a>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yushi Guan</a>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Nandita Vijaykumar</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">University of Toronto</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://drive.google.com/file/d/1pace-CUcQcJwgpoEp2hwvqBlWvw0jVp0/view?usp=sharing" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/LeoChengKX/large-scale-3r/tree/master" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser image -->
      <img src="static/images/teaser.jpg" id="tree" alt="Teaser Image" style="height: 100%; width: auto;" />
      <!-- TODO: Replace with your video description -->
      <!-- <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2> -->
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Recent advancements in neural visual geometry, including transformer-based models such as VGGT and Pi3, have achieved impressive accuracy on 3D reconstruction tasks. However, their reliance on full attention makes them fundamentally limited by GPU memory capacity, preventing them from scaling to large, unordered image collections. We introduce MERG3R, a training-free divide-and-conquer framework that enables geometric foundation models to operate far beyond their native memory limits. MERG3R first reorders and partitions unordered images into overlapping, geometrically diverse subsets that can be reconstructed independently. It then merges the resulting local reconstructions through an efficient global alignment and confidence-weighted bundle adjustment procedure, producing a globally consistent 3D model. Our framework is model-agnostic and can be paired with existing neural geometry models. Across large-scale datasets—including 7-Scenes, NRGBD, Tanks & Temples, and Cambridge Landmarks—MERG3R consistently improves reconstruction accuracy, memory efficiency, and scalability, enabling high-quality reconstruction when the dataset exceeds memory capacity limits.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper method -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Given an unordered set of images, we first sort them into a pseudo-video sequence, then split the sequence into multiple interleaved subsets. Each subset is independently processed by a geometric foundation model to produce local pointmaps and poses. The resulting clusters are aligned into a common reference frame and jointly refined via global bundle adjustment, producing a coherent final reconstruction.
          </p>
          <img src="static/images/pipeline_overview.jpg" id="tree" alt="Pipeline Overview Image" style="height: 100%; width: auto;" />
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper method -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/comparison1.png" alt="First research result visualization" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/comparison2.png" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Video Presentation -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <video controls style="width: 100%; border-radius: 8px;">
              <source src="static/videos/M3RGER_Method_Overview_ArtSci.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video presentation -->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <div class="bibtex-header">
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->


<!-- Particle Canvas -->
<canvas id="particle-canvas"></canvas>

<script>
/* ============================================================
   MERG3R Visual Enhancement Scripts
   ============================================================ */

// ── 1. Particle Field ──────────────────────────────────────
(function() {
  const canvas = document.getElementById('particle-canvas');
  const ctx = canvas.getContext('2d');
  let W, H, particles = [], lines = [];
  const COUNT = 90;
  const MAX_DIST = 130;

  function resize() {
    W = canvas.width  = window.innerWidth;
    H = canvas.height = window.innerHeight;
  }

  function rand(min, max) { return Math.random() * (max - min) + min; }

  function Particle() {
    this.x  = rand(0, W);
    this.y  = rand(0, H);
    this.vx = rand(-0.18, 0.18);
    this.vy = rand(-0.12, 0.12);
    this.r  = rand(0.8, 2.0);
    this.alpha = rand(0.3, 0.9);
    this.color = Math.random() > 0.6 ? '#63b3ed' : '#67e8f9';
  }
  Particle.prototype.update = function() {
    this.x += this.vx;
    this.y += this.vy;
    if (this.x < 0) this.x = W;
    if (this.x > W) this.x = 0;
    if (this.y < 0) this.y = H;
    if (this.y > H) this.y = 0;
  };

  for (let i = 0; i < COUNT; i++) particles.push(new Particle());

  function draw() {
    ctx.clearRect(0, 0, W, H);

    // draw connections
    for (let i = 0; i < COUNT; i++) {
      for (let j = i + 1; j < COUNT; j++) {
        const dx = particles[i].x - particles[j].x;
        const dy = particles[i].y - particles[j].y;
        const d  = Math.sqrt(dx*dx + dy*dy);
        if (d < MAX_DIST) {
          ctx.beginPath();
          ctx.strokeStyle = `rgba(99,179,237,${0.12 * (1 - d/MAX_DIST)})`;
          ctx.lineWidth = 0.5;
          ctx.moveTo(particles[i].x, particles[i].y);
          ctx.lineTo(particles[j].x, particles[j].y);
          ctx.stroke();
        }
      }
    }

    // draw particles
    particles.forEach(p => {
      p.update();
      ctx.beginPath();
      ctx.arc(p.x, p.y, p.r, 0, Math.PI * 2);
      ctx.fillStyle = p.color;
      ctx.globalAlpha = p.alpha;
      ctx.fill();
      ctx.globalAlpha = 1;
    });

    requestAnimationFrame(draw);
  }

  window.addEventListener('resize', resize);
  resize();
  draw();
})();

// ── 2. Scroll Reveal — see initScrollReveal() called at end of DOMContentLoaded ──

// ── 3. DOM Enhancements ───────────────────────────────────
document.addEventListener('DOMContentLoaded', function() {

  // 3a. MERG3R title: highlight the "3"
  const titleEl = document.querySelector('.publication-title');
  if (titleEl) {
    titleEl.innerHTML = titleEl.innerHTML.replace(
      'MERG3R',
      'MERG<span class="highlight-3">3</span>R'
    );
  }

  // 3b. Insert decorative coord tag + accent bar above title
  if (titleEl) {
    const coordTag = document.createElement('span');
    coordTag.className = 'coord-tag';
    coordTag.textContent = 'CVPR 2026';
    titleEl.parentNode.insertBefore(coordTag, titleEl);

    const bar = document.createElement('div');
    bar.className = 'hero-accent-bar';
    titleEl.insertAdjacentElement('afterend', bar);
  }

  // 3j. Measure ACTUAL text width (not element width) before char splitting
  const _ctx = document.createElement('canvas').getContext('2d');
  document.querySelectorAll('h2.title.is-3, h2.title:not(.publication-title)').forEach(h2 => {
    const style = window.getComputedStyle(h2);
    _ctx.font = `${style.fontWeight} ${style.fontSize} ${style.fontFamily}`;
    const w = _ctx.measureText(h2.textContent.trim()).width;
    h2.style.setProperty('--underline-width', Math.ceil(w) + 'px');
  });

  // 3k. Split section title text into individual char spans for wave hover
  document.querySelectorAll('h2.title.is-3, h2.title:not(.publication-title)').forEach(h2 => {
    const text = h2.textContent;
    h2.innerHTML = text.split('').map((char, i) => {
      const delay = i * 30;
      const c = char === ' ' ? '&nbsp;' : char;
      return `<span class="char" style="animation-delay:${delay}ms">${c}</span>`;
    }).join('');
  });

  // stat chips removed

  // 3e. Add reveal classes to sections (only those below the fold)
  document.querySelectorAll('section').forEach((s, i) => {
    const rect = s.getBoundingClientRect();
    if (rect.top >= window.innerHeight) {
      s.classList.add('reveal');
      if (i > 0) s.classList.add(`reveal-delay-${Math.min(i, 4)}`);
    }
  });

  // 3i. Grow accent bar on scroll
  const accentBar = document.querySelector('.hero-accent-bar');
  if (accentBar) {
    window.addEventListener('scroll', () => {
      const scrolled = window.scrollY;
      const maxScroll = document.documentElement.scrollHeight - window.innerHeight;
      const progress = Math.min(scrolled / (maxScroll * 0.4), 1); // fully grown at 40% scroll
      const width = 80 + Math.round(progress * (window.innerWidth * 0.55));
      accentBar.style.width = width + 'px';
      accentBar.style.opacity = 0.7 + progress * 0.3;
    }, { passive: true });
  }
  const revealEls = document.querySelectorAll('.reveal');
  const io = new IntersectionObserver((entries) => {
    entries.forEach(e => {
      if (e.isIntersecting) {
        e.target.classList.add('visible');
        io.unobserve(e.target);
      }
    });
  }, { threshold: 0.05, rootMargin: '0px 0px -40px 0px' });
  revealEls.forEach(el => io.observe(el));

  // 3f. Add glow dividers between major sections
  document.querySelectorAll('section + section').forEach(s => {
    const hr = document.createElement('hr');
    hr.className = 'glow-divider';
    s.parentNode.insertBefore(hr, s);
  });

  // 3g. Add subtle typing cursor to the coord tag
  const coordEl = document.querySelector('.coord-tag');
  if (coordEl) {
    const originalText = coordEl.textContent;
    coordEl.textContent = '';
    let i = 0;
    function type() {
      if (i < originalText.length) {
        coordEl.textContent += originalText[i++];
        setTimeout(type, 28);
      }
    }
    setTimeout(type, 400);
  }

});
</script>

</body>
</html>